{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6467b575-1c2b-4774-8af1-75b2ec5c6f71",
   "metadata": {},
   "source": [
    "# 1 Audio applications\n",
    "\n",
    "- **Audio classification**: easily categorize audio clips into different categories. You can identify whether a recording is of a barking dog or a meowing cat, or what music genre a song belongs to.\n",
    "- **Automatic speech recognition**: transform audio clips into text by transcribing them automatically. You can get a text representation of a recording of someone speaking, like ‚ÄúHow are you doing today?‚Äú. Rather useful for note taking!\n",
    "- **Speaker diarization**: Ever wondered who‚Äôs speaking in a recording? With ü§ó Transformers, you can identify which speaker is talking at any given time in an audio clip. Imagine being able to differentiate between ‚ÄúAlice‚Äù and ‚ÄúBob‚Äù in a recording of them having a conversation.\n",
    "- **Text to speech**: create a narrated version of a text that can be used to produce an audio book, help with accessibility, or give a voice to an NPC in a game. With ü§ó Transformers, you can easily do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf73927-72de-40f8-a0a4-e81cbf126d28",
   "metadata": {},
   "source": [
    "# 2 some demo\n",
    "\n",
    "## 2.1 demo: pipeline: audio classification\n",
    "\n",
    "### 2.1.1 load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9bbbe-20b6-4e93-94c3-901998fe6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd5dc3-1459-4eed-9f96-75adfffcf5c6",
   "metadata": {},
   "source": [
    "### 2.1.2 build transformer\n",
    "\n",
    "To classify an audio recording into a set of classes, we can use the audio-classification pipeline from ü§ó Transformers. \n",
    "\n",
    "In our case, we need a model that‚Äôs been fine-tuned for intent classification, and specifically on the MINDS-14 dataset. Luckily for us, the Hub has a model that does just that! Let‚Äôs load it by using the pipeline() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75cb77-d1bd-4fdb-b3c1-5828f814cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"audio-classification\",\n",
    "    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fb025-d292-4b07-8aa8-a6af64ae9f40",
   "metadata": {},
   "source": [
    "### 2.1.3 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f069fa-bce2-404a-8747-a001b480e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = minds[0]\n",
    "\n",
    "classifier(example[\"audio\"][\"array\"])\n",
    "\"\"\"\n",
    "[\n",
    "    {\"score\": 0.9631525278091431, \"label\": \"pay_bill\"},\n",
    "    {\"score\": 0.02819698303937912, \"label\": \"freeze\"},\n",
    "    {\"score\": 0.0032787492964416742, \"label\": \"card_issues\"},\n",
    "    {\"score\": 0.0019414445850998163, \"label\": \"abroad\"},\n",
    "    {\"score\": 0.0008378693601116538, \"label\": \"high_value_payment\"},\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7ac3f-b937-47f2-81ad-eceeed1c76e9",
   "metadata": {},
   "source": [
    "### 2.1.4 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342b2c8-a29e-45b3-8036-d4e2781259b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = minds.features[\"intent_class\"].int2str\n",
    "id2label(example[\"intent_class\"])\n",
    "# \"pay_bill\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dc3ac-e7c9-4ca6-942e-99e93cc7f3ac",
   "metadata": {},
   "source": [
    "## 2.2 demo: pipeline: automatic speech recognization\n",
    "\n",
    "demo for english-AU\n",
    "\n",
    "```python\n",
    "# 1 build transformer\n",
    "\n",
    "from transformers import pipeline\n",
    "asr = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "# 2 predict\n",
    "example = minds[0]\n",
    "asr(example[\"audio\"][\"array\"])\n",
    "\n",
    "# 3 evaluate\n",
    "example[\"english_transcription\"]\n",
    "```\n",
    "\n",
    "demo for German\n",
    "\n",
    "```python\n",
    "# 1 prepare dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"de-DE\", split=\"train\")\n",
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "# 2 build transformer\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"maxidl/wav2vec2-large-xlsr-german\")\n",
    "\n",
    "# 3 predict\n",
    "\n",
    "example = minds[0]\n",
    "asr(example[\"audio\"][\"array\"])\n",
    "\n",
    "# 4 evaluate\n",
    "\n",
    "example[\"transcription\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0e66d-6ad9-44bb-9a97-19ca38a172a7",
   "metadata": {},
   "source": [
    "## 2.3 demo: pipeline: audio generation\n",
    "\n",
    "### 2.3.1 Text-To-Speech: english\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "\n",
    "text = \"Ladybugs have had important roles in culture and religion, being associated with luck, love, fertility and prophecy. \"\n",
    "output = pipe(text)\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n",
    "```\n",
    "### 2.3.2 Text-To-Speech: German\n",
    "\n",
    "The model that we‚Äôre using with the pipeline, Bark, is actually multilingual, so we can easily substitute the initial text with a text in, say, French, and use the pipeline in the exact same way.\n",
    "\n",
    "```python\n",
    "fr_text = \"Contrairement √† une id√©e r√©pandue, le nombre de points sur les √©lytres d'une coccinelle ne correspond pas √† son √¢ge, ni en nombre d'ann√©es, ni en nombre de mois. \"\n",
    "output = pipe(fr_text)\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n",
    "```\n",
    "\n",
    "### 2.3.3 Text-To-Speech: Sing song\n",
    "\n",
    "Not only is this model multilingual, it can also generate audio with non-verbal communications and singing. Here‚Äôs how you can make it sing:\n",
    "\n",
    "```python\n",
    "song = \"‚ô™ In the jungle, the mighty jungle, the ladybug was seen. ‚ô™ \"\n",
    "output = pipe(song)\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n",
    "```\n",
    "\n",
    "### 2.3.3 Generate music\n",
    "\n",
    "```python\n",
    "music_pipe = pipeline(\"text-to-audio\", model=\"facebook/musicgen-small\")\n",
    "\n",
    "text = \"90s rock song with electric guitar and heavy drums\"\n",
    "\n",
    "forward_params = {\"max_new_tokens\": 512}\n",
    "\n",
    "output = music_pipe(text, forward_params=forward_params)\n",
    "Audio(output[\"audio\"][0], rate=output[\"sampling_rate\"])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
